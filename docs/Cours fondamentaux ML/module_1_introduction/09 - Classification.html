
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Classification: K-nearest-neighbours &#8212; IA-Z</title>
    
  <link href="../../../_static/css/theme.css" rel="stylesheet">
  <link href="../../../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="../../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/myfile.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../../../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
    <script src="../../../_static/jquery.js"></script>
    <script src="../../../_static/underscore.js"></script>
    <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/clipboard.min.js"></script>
    <script src="../../../_static/copybutton.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../../_static/sphinx-book-theme.d59cb220de22ca1c485ebbdc042f0030.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="next" title="Classification avec KNN" href="09%20-%20Classification%20avec%20KNN.html" />
    <link rel="prev" title="Compromis biais-variance" href="08%20-%20Compromis%20biais-variance.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../../../_static/logo.jpeg" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">IA-Z</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../README.html">
   Sommaire
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Apprentissage automatique
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="01%20-%20Pourquoi%20le%20ML%20%26%20information%20gr%C3%A2ce%20%C3%A0%20la%20data.html">
   Pourquoi le Machine Learning ?
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="02%20-%20Elements%20de%20definition.html">
     Éléments de définition
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="03%20-%20Regression%20lineaire.html">
     Introduction à la régression : la régression linéaire
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="05%20-%20Generalisation.html">
     Généralisation d’un modèle de Machine Learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="06%20-%20R%C3%A9gularisation%20%26%20tradeoff%20biais-variance%20-%20une%20introduction.html">
     Régularisation &amp; tradeoff biais-variance : une introduction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="07%20-%20R%C3%A9gularisation%20d%27un%20mod%C3%A8le.html">
     Régularisation d’un modèle
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="08%20-%20Compromis%20biais-variance.html">
     Compromis biais-variance
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Classification: K-nearest-neighbours
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="09%20-%20Classification%20avec%20KNN.html">
     Classification avec KNN
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="10%20-%20Clustering.html">
     Clustering
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="11%20-%20Feature%20engineering%20%26%20cleaning.html">
     Feature Engineering
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Traitement automatique de la langue
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../NLP/chapitre1_introduction/1_Introduction.html">
   Chapitre I: Introduction
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../NLP/chapitre1_introduction/2_DonneesTextuelles.html">
     Etude des données textuelles
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../NLP/chapitre2_notionsgenerales/3_ModStatLangage.html">
   Chapitre II: Notions générales
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../NLP/chapitre2_notionsgenerales/4_ModLangues.html">
     Modèles de langues
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../NLP/chapitre2_notionsgenerales/5_Embeddings.html">
     Embeddings
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Vision par ordinateur
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../Cours_CV/0_intro.html">
   Computer Vision
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../Cours_CV/1_Image_processing.html">
   Section 1 Image processing techniques
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../Cours_CV/2_ML_CV.html">
   Machine Learning for Computer Vision
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../Cours_CV/3_CNN.html">
   Convolutional Neural Network
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../Cours_CV/4_Modern_CNN.html">
   Modern Convolutional Neural Networks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../Cours_CV/5_CV_tasks.html">
   Computer Vision tasks
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Apprentissage par renforcement
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../Cours%20RL/module_1_introduction/1%20-%20Introduction.html">
   Introduction au Reinforcement learning
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Cours%20RL/module_1_introduction/3%20-%20Processus%20de%20d%C3%A9cision%20markoviens.html">
     Processus de décision markoviens (MDPs)
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../Cours%20RL/module_2_notions_avancees/6%20-%20Algorithmes%20de%20RL.html">
   Algorithmes de RL
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Cours%20RL/module_2_notions_avancees/7%20-%20Monte%20Carlo.html">
     Monte-Carlo
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Hors-série
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../Cours%20annexes/mener_une_recherche.html">
   Mener une recherche internet efficacement
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../../_sources/docs/Cours fondamentaux ML/module_1_introduction/09 - Classification.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
                onclick="printPdf(this)" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/ia-z/ia-z"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/ia-z/ia-z/issues/new?title=Issue%20on%20page%20%2Fdocs/Cours fondamentaux ML/module_1_introduction/09 - Classification.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/ia-z/ia-z/master?urlpath=tree/docs/Cours fondamentaux ML/module_1_introduction/09 - Classification.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../../../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show noprint">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#mesure-de-distance">
   Mesure de Distance
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#nombre-de-voisins">
   Nombre de voisins
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#agregation-des-resultats">
   Agrégation des résultats
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#classification">
     Classification
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#regression">
     Régression
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#point-important">
   Point Important
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#a-retenir">
   À retenir
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#implementation">
   Implémentation
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#sources">
   Sources
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Classification: K-nearest-neighbours</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#mesure-de-distance">
   Mesure de Distance
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#nombre-de-voisins">
   Nombre de voisins
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#agregation-des-resultats">
   Agrégation des résultats
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#classification">
     Classification
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#regression">
     Régression
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#point-important">
   Point Important
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#a-retenir">
   À retenir
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#implementation">
   Implémentation
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#sources">
   Sources
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            
              <div>
                
  <div class="cell tag_remove-input docutils container">
</div>
<div class="tex2jax_ignore mathjax_ignore section" id="classification-k-nearest-neighbours">
<h1>Classification: K-nearest-neighbours<a class="headerlink" href="#classification-k-nearest-neighbours" title="Permalink to this headline">¶</a></h1>
<p>Si vous vous rappelez du chapitre 2, le Machine Learning peut être utilisé pour deux tâches: la régression et la classification. Nous avons introduit la régression dans le chapitre précédent, il est donc temps de présenter la classification.
L’approche la plus simple et intuitive est de partir du principe que les points de données de même catégorie se ressemblent. En partant de cette hypothèse, nous pouvons créer un modèle qui va comparer le point que nous souhaitons prédire (<span class="math notranslate nohighlight">\(x_{new}\)</span>) avec ceux qui sont déjà connus et aggréger les plus proches.
C’est exactement ce que fait l’algorithme K-nearest-neighbours (“k voisins les plus proches”). Il va d’abord stocker les données d’entraînement avec leurs labels respectifs. Ensuite, lors de la prédiction, il va trouver les <span class="math notranslate nohighlight">\(k\)</span> voisins les plus proches et aggréger leur labels respectifs.</p>
<p>Il faudra résoudre plusieurs problèmes avant de pouvoir utiliser KNN. En effet, il faut déterminer le nombre de voisins (<span class="math notranslate nohighlight">\(k\)</span>) à prendre en compte, la façon de calculer les distances ainsi que la façon d’aggréger les voisins.</p>
<div class="section" id="mesure-de-distance">
<h2>Mesure de Distance<a class="headerlink" href="#mesure-de-distance" title="Permalink to this headline">¶</a></h2>
<p>Nous pouvons utiliser plusieurs méthodes de mesure différentes comme la mesure Euclidienne (l2-norm), celle de Manhattan (l1-norm), et d’autres. Le mesure la plus simple est la distance euclidienne qui calcule la distance dans l’espace cartésien.</p>
<div class="math notranslate nohighlight">
\[distance(x_{new},x_n)=\sqrt{\sum_{a=1}^A(x_{new,a}-x_{n,a})^2}\]</div>
<p><span class="math notranslate nohighlight">\(A\)</span> représente tous les attributs.</p>
<p>Par facilité nous pouvons omettre la racine carrée et réécrire la formule en utilisant des vecteurs:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align}
    distance(x_{new},x_n)^2 &amp;= \sum_{a=1}^A(x_{new,a}-x_{n,a})^2 \\
    &amp;= \sum_{a=1}^A(x_{new,a}-x_{n,a})^T(x_{new,a}-x_{a,d}) \\
    &amp;= (x_{new}-x_n)^T(x_{new}-x_n)
\end{align}\end{split}\]</div>
<p>Cette formulation est la plus répendue et est pratique car les ordinateurs sont particulièrement performants pour le calcul vectoriel.</p>
<p>Il est aussi possible de calculer la distance dans un autre espace grâce aux kernels. Cependant, cette méthode ne sera pas expliqué dans ce module.</p>
<blockquote>
<div><p>Vous aurez remarqué que la distance d’un point s’évalue sur base de la différence entre chaque attribut.
C’est pour cette raison qu’il faut de préférence normaliser les données quand on utilise KNN.
Imaginons que nous avons un attributs dont les valeurs se trouvent entre 0 et 1, et un autre entre -100 et 100.
Le second attribut aura plus de poids dans la mesure de distance car il aura de plus grande valeurs comparé au premier.
Par exemple nous avons deux point; (0.5, 50) et (0.45, 0).
La distance entre les deux premier attributs est de <span class="math notranslate nohighlight">\((0.5-0.45)²=0.0025\)</span> et entre les deuxièmes <span class="math notranslate nohighlight">\((50-0)²=2500\)</span>.
Ils auront donc une distance de 2500.0025 entre les deux alors qu’ils sont très proche dans le premier attribut.
La normalisation est encore plus importante quand on décide d’utiliser des poids lors de l’aggrégation.</p>
</div></blockquote>
</div>
<div class="section" id="nombre-de-voisins">
<h2>Nombre de voisins<a class="headerlink" href="#nombre-de-voisins" title="Permalink to this headline">¶</a></h2>
<p>Maintenant que nous savons comment la distance sera mesurée il faut savoir combien de voisins nous devons prendre en compte. Pour voir les délimitations (bordures de décisions) entre 2 classes, nous pouvons créer un graphiques comme celui qui suit. Ce graphique présente les deux catégories ainsi que la bordure de décision.</p>
<div class="figure align-default" id="ks-fig">
<a class="reference internal image-reference" href="../../../_images/ks.png"><img alt="Influence du nombre de voisins sur la bordure de décision" src="../../../_images/ks.png" style="width: 750px;" /></a>
<p class="caption"><span class="caption-number">Fig. 6 </span><span class="caption-text">Influence du nombre de voisins sur la bordure de décision</span><a class="headerlink" href="#ks-fig" title="Permalink to this image">¶</a></p>
</div>
<p>Nous pouvons voir que si nous utilisons 1 voisin, nous avons une poches dans les bleus où le point sera classifié comme orange. Utiliser 5 voisins semble suivre la forme de nos données alors qu’en utiliser plus linéarise la bordure. Bien que la meilleur façon de choisir le nombre de voisins en utilisants des mesures tel que l’accuracy ou le F1-score, créer un graphique nous permet de visualier la bordure et de comprendre le modèle.</p>
<p><strong>Une image est présente pour montrer l’impact du nombre de voisins</strong></p>
<p>Il est dont primordial de déterminer le nombre optimal de voisins à prendre en compte. Le plus efficace et simple est d’utiliser les données d’entraînement pour trouver ce nombre. Nous pouvons déterminer une liste de nombres des voisins et entraîner chaque version avec l’ensemble d’entraînement et de l’évaluer sur l’ensemble de validation. La version du modèle la plus performante est celle que nous garderons.</p>
<p>Un autre facteur déterminant est la balance des données. Si notre dataset d’entraînement n’est pas balancé et que nous avons 10 points qui sont de classe 1 et 90 de classe 2, utiliser un k &gt; 10 va toujours prédire 2.</p>
</div>
<div class="section" id="agregation-des-resultats">
<h2>Agrégation des résultats<a class="headerlink" href="#agregation-des-resultats" title="Permalink to this headline">¶</a></h2>
<p>La dernière chose à déterminer est la façon dont on va aggréger les voisins. KNN est utilisé plus souvent dans les tâches de classification mais ce modèle peut aussi être utilisé pour de la régression.</p>
<div class="section" id="classification">
<h3>Classification<a class="headerlink" href="#classification" title="Permalink to this headline">¶</a></h3>
<p>Le plus simple est d’attribuer la classe qui est la plus présente dans les voisins qui ont été selectionnés. Dans certain cas, on voudra prendre la distance des voisins en compte. En effet, il est possible que sur 5 voisins, notre point soit collé à deux points d’une classe mais qu’il ait 3 autres voisins assez distants. Si nous utilisons la première méthode, le point sera classifié comme appartenant à la même classe que les trois points distant. Ce problème peut-être résolu en prenant la distance en compte. Pour ce faire, on attribue un poids à chaque point. Si l’influence d’un voisin est inversement proportionnelle à sa distance, le nouveau point sera correctement classifié
chaque vote, tel que l’inverse de la distance, les deux points proches auront l’avantage et notre nouveau point sera correctement classifié.</p>
</div>
<div class="section" id="regression">
<h3>Régression<a class="headerlink" href="#regression" title="Permalink to this headline">¶</a></h3>
<p>Dans le cas de régression, nous prendrons la moyenne de chaque voisins. Dans ce cas nous pouvons aussi prendre la distance en compte.</p>
</div>
</div>
<div class="section" id="point-important">
<h2>Point Important<a class="headerlink" href="#point-important" title="Permalink to this headline">¶</a></h2>
<p>Nous savons que dans le cadre de la classification, KNN part du principe que les échantillons d’une même catégorie sont proches les uns des autres et que, idéalement, les données d’entraînement sont équilibrée. Un autre point important à prendre en compte est ce qu’on appelle “la malédiction de la dimensionnalité”. Le volume d’une espace de données augumente exponentielement avec le nombre d’attributs, ainsi nous avons besoin d’une quantité exponentielle d’échantillons, sinon nous aurons des espaces quasi vides et la distance entre chaque échantillon augmentera. KNN évalue la distance entre un point et un autre en fonction de la distance dans chaque attribut (<span class="math notranslate nohighlight">\((x_{new,a}-x_{n,a})^2\)</span>), il sera donc de plus en plus difficile pour KNN de trouver les voisins correctement.</p>
</div>
<div class="section" id="a-retenir">
<h2>À retenir<a class="headerlink" href="#a-retenir" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>Lors de la classification, KNN part du principe que les échantillons de la même catégorie sont proches l’un de l’autre.</p></li>
<li><p>KNN est un modèle assez simple mais qui est modulable afin de correspondre le plus possible à notre tâche.</p></li>
<li><p>Il faut faire attention à l’équilibre de l’ensemble d’entraînement.</p></li>
<li><p>Ce modèle peut-être utilisé pour des tâches de classification ainsi que de régression.</p></li>
</ul>
</div>
<div class="section" id="implementation">
<h2>Implémentation<a class="headerlink" href="#implementation" title="Permalink to this headline">¶</a></h2>
<p>Pour faciliter l’implémentation nous allons utiliser numpy. Nous allons aussi suivre l’architecture de scikit learn (Sklearn), c’est à dire que notre modèle possède une fonction <strong>.fit</strong> pour l’entraîner et <strong>.predict</strong> pour la prédiction.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="sd">&#39;&#39;&#39;</span>
<span class="sd">-- Création de l&#39;ensemble de données --</span>
<span class="sd">Notez que j&#39;utilise une distribution normale ce qui permet d&#39;avoir tous les points d&#39;une même classe relativement proches.</span>
<span class="sd">De plus, je génère un ensemble équilibré.</span>
<span class="sd">&#39;&#39;&#39;</span>

<span class="n">elements</span> <span class="o">=</span> <span class="mi">50</span>
<span class="n">random_state</span> <span class="o">=</span> <span class="mi">42</span>
<span class="n">K</span> <span class="o">=</span> <span class="mi">5</span>

<span class="k">def</span> <span class="nf">generate_data</span><span class="p">(</span><span class="n">elements</span><span class="p">,</span> <span class="n">random_state</span><span class="p">):</span>
    <span class="n">rng</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">RandomState</span><span class="p">(</span><span class="n">random_state</span><span class="p">)</span>

    <span class="n">classes_x</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.55</span><span class="p">,</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="n">elements</span><span class="p">))</span>
    <span class="n">classes_y</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mf">0.55</span><span class="p">,</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="n">elements</span><span class="p">))</span>
    <span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">elements</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">elements</span><span class="p">)))</span>
    <span class="n">dset</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span><span class="n">elements</span><span class="o">*</span><span class="mi">2</span><span class="p">))</span>

    <span class="n">dset</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">classes_x</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">classes_y</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
    <span class="n">dset</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">classes_x</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">classes_y</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>

    <span class="k">return</span> <span class="n">dset</span><span class="p">,</span> <span class="n">labels</span>

<span class="sd">&#39;&#39;&#39;</span>
<span class="sd">-- Implémentation du modèle --</span>
<span class="sd">&#39;&#39;&#39;</span>

<span class="k">class</span> <span class="nc">KNN</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">K</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">K</span> <span class="o">=</span> <span class="n">K</span>
    

    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">data</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">labels</span> <span class="o">=</span> <span class="n">labels</span>
    
    
    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data_point</span><span class="p">):</span>
        <span class="n">preds</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">for</span> <span class="n">dp</span> <span class="ow">in</span> <span class="n">data_point</span><span class="p">:</span>
            <span class="n">distances</span> <span class="o">=</span> <span class="p">[]</span>

            <span class="k">for</span> <span class="n">point</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">:</span>
                <span class="n">distances</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">distance</span><span class="p">(</span><span class="n">dp</span><span class="p">,</span> <span class="n">point</span><span class="p">))</span> 

            <span class="n">sorted_distances</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">distances</span><span class="p">)</span>

            <span class="n">preds</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">bincount</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="p">[</span><span class="n">sorted_distances</span><span class="p">[:</span><span class="bp">self</span><span class="o">.</span><span class="n">K</span><span class="p">]]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">))</span><span class="o">.</span><span class="n">argmax</span><span class="p">())</span>
        
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">preds</span><span class="p">)</span>
    

    <span class="k">def</span> <span class="nf">distance</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x_new</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">x_new</span><span class="o">-</span><span class="n">x</span><span class="p">,</span> <span class="n">x_new</span><span class="o">-</span><span class="n">x</span><span class="p">),</span> <span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Maintenant que nous avons un modèle et une méthode de génération de données, nous pouvons l’utiliser pour faire des prédictions. Nous allons générer 10 points de chaque classe. Vu que nous avons un ensemble équilibré et binaire, nous pouvons utiliser l’accuracy. Cette mesure calcule le pourcentage de mauvaise prédiction.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># On génère les données d&#39;entraînement et on &quot;fit&quot; le modèle</span>
<span class="n">train_set</span><span class="p">,</span> <span class="n">train_labels</span> <span class="o">=</span> <span class="n">generate_data</span><span class="p">(</span><span class="n">elements</span><span class="p">,</span> <span class="n">random_state</span><span class="p">)</span>

<span class="c1"># Ensuite on le teste en générant le set de test </span>
<span class="n">elements</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">test_set</span><span class="p">,</span> <span class="n">test_labels</span> <span class="o">=</span> <span class="n">generate_data</span><span class="p">(</span><span class="n">elements</span><span class="p">,</span> <span class="n">random_state</span><span class="p">)</span>
    
<span class="n">model</span> <span class="o">=</span> <span class="n">KNN</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_set</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">)</span>

<span class="n">preds</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_set</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">preds</span> <span class="o">!=</span> <span class="n">test_labels</span><span class="p">)</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">test_labels</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.1
</pre></div>
</div>
</div>
</div>
<p>Nous avons deux erreurs sur les 20 points, ce qui donne une accuracy de 0.1. C’est plutôt pas mal. Pour comprendre d’où elles viennent, nous pouvons tracer la bordure avec les points d’entraînements et de test.</p>
<!--
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd

from matplotlib.colors import ListedColormap
from sklearn.neighbors import KNeighborsClassifier

h = .02
cmap_light = ListedColormap(['#FFAAAA', '#AAFFAA', '#AAAAFF'])
cmap_bold = ListedColormap(['#FF0000', '#00FF00', '#0000FF'])

random_state = 42
rng=np.random.RandomState(random_state )

x1 = rng.normal(0, 0.55, 50)
y1 = rng.normal(0, 0.55, 50)

x2 = rng.normal(1, 0.55, 50)
y2 = rng.normal(1, 0.55, 50)

x = np.concatenate((x1, x2))
y = np.concatenate((y1, y2))
labels = np.concatenate((np.full(len(x1), 0), np.full(len(x2), 1)))

f, axis = plt.subplots(1, 4, sharey=True, figsize=(15,15))

line = 0

for ind, k in enumerate([1, 5, 10, 15]):
    
    if ind > 3:
        ind -= 4
        line = 1
        
    X = np.transpose(np.array([x,y]))
                        
    kNN = KNeighborsClassifier(k)
    kNN.fit(X, labels)

    np.transpose(X)

    x_min, x_max = X[:, 0].min() - 0.5, X[:, 0].max() + 0.5
    y_min, y_max = X[:, 1].min() - 0.5, X[:, 1].max() + 0.5

    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),
                         np.arange(y_min, y_max, h))

    Z = kNN.predict(np.c_[xx.ravel(), yy.ravel()])

    # Put the result into a color plot
    Z = Z.reshape(xx.shape)

    #plt.figure()
    axis[ind].pcolormesh(xx, yy, Z, cmap=cmap_light)
    # Plot also the training points
    axis[ind].scatter(X[:,0], X[:,1], c=labels, cmap=cmap_bold)
    axis[ind].set_xlim(xx.min(), xx.max())
    axis[ind].set_ylim(yy.min(), yy.max())
    axis[ind].set(aspect=1)
    axis[ind].set_title(f"k={k}")
    
plt.tight_layout()
plt.savefig("choix_des_k", bbox_inches='tight', pad_inches=0)
plt.show()
--><div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Plot the figures</span>
<span class="kn">import</span> <span class="nn">plotly.express</span> <span class="k">as</span> <span class="nn">px</span>
<span class="kn">import</span> <span class="nn">plotly.graph_objects</span> <span class="k">as</span> <span class="nn">go</span>

<span class="c1"># Création du mesh pour voir la bordure de décision</span>
<span class="n">mesh_size</span> <span class="o">=</span> <span class="mf">.02</span>
<span class="n">margin</span> <span class="o">=</span> <span class="mf">0.25</span>

<span class="c1"># Create a mesh grid on which we will run our model</span>
<span class="n">x_min</span><span class="p">,</span> <span class="n">x_max</span> <span class="o">=</span> <span class="n">train_set</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">()</span> <span class="o">-</span> <span class="n">margin</span><span class="p">,</span> <span class="n">train_set</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">+</span> <span class="n">margin</span>
<span class="n">y_min</span><span class="p">,</span> <span class="n">y_max</span> <span class="o">=</span> <span class="n">train_set</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">()</span> <span class="o">-</span> <span class="n">margin</span><span class="p">,</span> <span class="n">train_set</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">+</span> <span class="n">margin</span>
<span class="n">xrange</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">x_min</span><span class="p">,</span> <span class="n">x_max</span><span class="p">,</span> <span class="n">mesh_size</span><span class="p">)</span>
<span class="n">yrange</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">y_min</span><span class="p">,</span> <span class="n">y_max</span><span class="p">,</span> <span class="n">mesh_size</span><span class="p">)</span>
<span class="n">xx</span><span class="p">,</span> <span class="n">yy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">xrange</span><span class="p">,</span> <span class="n">yrange</span><span class="p">)</span>

<span class="c1"># Les couleurs pour la bordure</span>
<span class="n">color_scale</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;rgb(255, 255, 255)&quot;</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="s2">&quot;rgb(122, 122, 122)&quot;</span><span class="p">]]</span>

<span class="n">preds</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_set</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
<span class="n">preds</span><span class="p">[</span><span class="n">preds</span> <span class="o">!=</span> <span class="n">test_labels</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>    

<span class="n">Z</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">c_</span><span class="p">[</span><span class="n">xx</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span> <span class="n">yy</span><span class="o">.</span><span class="n">ravel</span><span class="p">()]))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">str</span><span class="p">)</span>
<span class="n">Z</span> <span class="o">=</span> <span class="n">Z</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">xx</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">go</span><span class="o">.</span><span class="n">Figure</span><span class="p">()</span>

<span class="n">fig</span><span class="o">.</span><span class="n">add_trace</span><span class="p">(</span>
    <span class="n">go</span><span class="o">.</span><span class="n">Contour</span><span class="p">(</span>
        <span class="n">x</span><span class="o">=</span><span class="n">xrange</span><span class="p">,</span>
        <span class="n">y</span><span class="o">=</span><span class="n">yrange</span><span class="p">,</span>
        <span class="n">z</span><span class="o">=</span><span class="n">Z</span><span class="p">,</span>
        <span class="n">colorscale</span><span class="o">=</span><span class="n">color_scale</span><span class="p">,</span>
        <span class="n">showscale</span><span class="o">=</span><span class="kc">False</span>
    <span class="p">)</span>
<span class="p">)</span>

<span class="n">fig</span><span class="o">.</span><span class="n">add_trace</span><span class="p">(</span>
    <span class="n">go</span><span class="o">.</span><span class="n">Scatter</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">train_set</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="n">train_labels</span> <span class="o">==</span> <span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">train_set</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="n">train_labels</span><span class="o">==</span><span class="mi">0</span><span class="p">],</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;markers&quot;</span><span class="p">,</span>
      <span class="n">marker</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">color</span><span class="o">=</span><span class="s2">&quot;rgb(2,48,71)&quot;</span><span class="p">),</span> <span class="c1">#showlegend = False,</span>
       <span class="n">name</span><span class="o">=</span><span class="s2">&quot;entraînement: 0&quot;</span>
    <span class="p">)</span>
<span class="p">)</span>

<span class="n">fig</span><span class="o">.</span><span class="n">add_trace</span><span class="p">(</span>
    <span class="n">go</span><span class="o">.</span><span class="n">Scatter</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">train_set</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="n">train_labels</span> <span class="o">==</span> <span class="mi">1</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">train_set</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="n">train_labels</span><span class="o">==</span><span class="mi">1</span><span class="p">],</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;markers&quot;</span><span class="p">,</span>
      <span class="n">marker</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">color</span><span class="o">=</span><span class="s2">&quot;rgb(255,158,2)&quot;</span><span class="p">),</span> <span class="c1">#showlegend = False,</span>
       <span class="n">name</span><span class="o">=</span><span class="s2">&quot;entraînement: 1&quot;</span>
    <span class="p">)</span>
<span class="p">)</span>

<span class="n">fig</span><span class="o">.</span><span class="n">add_trace</span><span class="p">(</span>
    <span class="n">go</span><span class="o">.</span><span class="n">Scatter</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">test_set</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="n">preds</span> <span class="o">==</span> <span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">test_set</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="n">preds</span><span class="o">==</span><span class="mi">0</span><span class="p">],</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;markers&quot;</span><span class="p">,</span>
      <span class="n">marker</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">color</span><span class="o">=</span><span class="s2">&quot;rgb(28,128,178)&quot;</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mf">7.5</span><span class="p">,</span> <span class="n">line</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">width</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;DarkSlateGrey&#39;</span><span class="p">)),</span>
                  <span class="n">name</span><span class="o">=</span><span class="s2">&quot;Correctement Prédit comme 0&quot;</span>
    <span class="p">)</span>
<span class="p">)</span>

<span class="n">fig</span><span class="o">.</span><span class="n">add_trace</span><span class="p">(</span>
    <span class="n">go</span><span class="o">.</span><span class="n">Scatter</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">test_set</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="n">preds</span> <span class="o">==</span> <span class="mi">1</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">test_set</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="n">preds</span><span class="o">==</span><span class="mi">1</span><span class="p">],</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;markers&quot;</span><span class="p">,</span>
      <span class="n">marker</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">color</span><span class="o">=</span><span class="s2">&quot;rgb(176,78,68)&quot;</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mf">7.5</span><span class="p">,</span> <span class="n">line</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">width</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;DarkSlateGrey&#39;</span><span class="p">)),</span>
                  <span class="n">name</span><span class="o">=</span><span class="s2">&quot;Correctement Prédit comme 1&quot;</span>
    <span class="p">)</span>
<span class="p">)</span>

<span class="n">fig</span><span class="o">.</span><span class="n">add_trace</span><span class="p">(</span>
    <span class="n">go</span><span class="o">.</span><span class="n">Scatter</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">test_set</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="n">preds</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">test_set</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="n">preds</span><span class="o">==-</span><span class="mi">1</span><span class="p">],</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;markers&quot;</span><span class="p">,</span>
      <span class="n">marker</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">color</span><span class="o">=</span><span class="s2">&quot;rgb(255,0,0)&quot;</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">line</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">width</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;DarkSlateGrey&#39;</span><span class="p">)),</span>
                  <span class="n">name</span><span class="o">=</span><span class="s2">&quot;Erreur Prédit comme 0 au lieu de 1&quot;</span>
    <span class="p">)</span>
<span class="p">)</span>

<span class="n">fig</span><span class="o">.</span><span class="n">update_layout</span><span class="p">(</span><span class="n">height</span><span class="o">=</span><span class="mi">800</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mi">800</span><span class="p">,</span> <span class="n">title_text</span><span class="o">=</span><span class="s2">&quot;La bordure de décision de notre modèle&quot;</span><span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="s1">&#39;iframe&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><iframe
    scrolling="no"
    width="820px"
    height="820"
    src="iframe_figures/figure_8.html"
    frameborder="0"
    allowfullscreen
></iframe>
</div></div>
</div>
<p>Nous pouvons voir que que les deux erreurs sont deux points qui sont de classe 1 mais prédits de classe 0 par le modèle.
Même certains points du dataset d’entraînement ne sont pas tous bien classifier par le modèle (ceux du mauvais côté de la bordure de décision).
On peut toujours adapter le nombre de voisins afin de réduire l’erreur mais il faut faire attention à l’overfitting !</p>
</div>
<div class="section" id="sources">
<h2>Sources<a class="headerlink" href="#sources" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>Cours “Algorithms for Machine Learning and Inference” de Chalmers University of Technology</p></li>
</ul>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./docs/Cours fondamentaux ML/module_1_introduction"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            
                <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="08%20-%20Compromis%20biais-variance.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Compromis biais-variance</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="09%20-%20Classification%20avec%20KNN.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Classification avec KNN</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            
        </div>
    </div>
    <footer class="footer">
  <p>
    
      By Communauté IA-Z<br/>
    
        &copy; Copyright 2021.<br/>
  </p>
</footer>
</main>


      </div>
    </div>
  
  <script src="../../../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>